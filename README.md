# Structured Output Evaluation for LLMs

This repository contains the implementation and experiments for evaluating structured outputs (primarily JSON) generated by large language models (LLMs). The work was conducted as part of an EMNLP project titled **"Evaluating Structured Outputs in NLP: Metrics, Models, and Beyond."**

## ğŸ“˜ Project Overview

Modern LLMs are increasingly expected to generate structured outputs for use in APIs, UIs, and other downstream systems. However, standard NLP metrics like BLEU and ROUGE fail to capture the structural and semantic nuances of formats like JSON. This project proposes structure-aware evaluation techniques that better reflect the accuracy, fidelity, and usefulness of such outputs.

## ğŸ§ª Core Methods

The evaluation framework is based on:

- **Tree-Based Linearization**: Converts JSONs to flattened strings using different tree traversal strategies (pre-order, post-order, in-order) to enable the use of ROUGE and BERTScore.
- **Node-to-Node Semantic Similarity**: Compares each node in the reference and predicted JSONs using BERT embeddings to assess local semantic fidelity.

## ğŸ› ï¸ Code Modules

| File | Description |
|------|-------------|
| `ai_evaluate.py` | Runs evaluations using LLM-as-a-judge approach (GPT-4o-mini). |
| `analyse_node_to_node_scores.py` | Analyzes node-level BERT similarity scores. |
| `calculate_scores.py` | Computes ROUGE and BERTScore over tree traversals. |
| `clean.py` | Cleans and filters model outputs and references. |
| `generate_report.py` | Compiles evaluation results into final report form. |
| `llm_json_convert.py` | Converts Wikipedia text to JSON using LLMs. |
| `node_to_node.py` | Computes node-to-node semantic similarity using embeddings. |

## ğŸ“Š Evaluation Setup

- **Data**: Wikipedia-derived dataset with structured JSON outputs from Qwen2.5-14B as pseudo-references.
- **Models**: Qwen2.5-3B and Phi-3-mini-128k-instruct.
- **Metrics**: ROUGE, BERTScore on traversals, node-level BERT similarity, and LLM-as-a-judge scores.

## ğŸ” Key Findings

- Traversal-based BERTScore correlates best with LLM judgments.
- ROUGE-1 is a useful structural metric, but less semantically aware.
- Phi-3 showed strong semantic performance; Qwen-3B had better structural alignment.

## ğŸ“š References

For detailed methodology and results, see the full EMNLP project report (`report.pdf`).


### If any queries contact
* Hardik Mittal (hardik.mittal@research.iiit.ac.in)
* Ayan Datta (ayan.datta@research.iiit.ac.in)
